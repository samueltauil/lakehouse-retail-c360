{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "6b149088-5a56-4062-a866-06a50c7631c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# SDP pipeline log analysis\n",
    "\n",
    "<img style=\"float:right\" width=\"500\" src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/retail/lakehouse-churn/lakehouse-retail-c360-dashboard-dlt-stat.png?raw=true\">\n",
    "\n",
    "\n",
    "Each SDP Pipeline saves events and expectations metrics in the Storage Location defined on the pipeline. From this table we can see what is happening and the quality of the data passing through it.\n",
    "\n",
    "You can leverage the expecations directly as a SQL table with Databricks SQL to track your expectation metrics and send alerts as required. \n",
    "\n",
    "This notebook extracts and analyses expectation metrics to build such KPIS.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=7405609900705693&notebook=%2F01-Data-ingestion%2F01.1-SDP-SQL%2F01.2-SDP-churn-expectation-dashboard-data-prep&demo_name=lakehouse-retail-c360&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-retail-c360%2F01-Data-ingestion%2F01.1-SDP-SQL%2F01.2-SDP-churn-expectation-dashboard-data-prep&version=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56c3a699-8348-4ccd-9920-477b8c5ee0bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Accessing the Spark Declarative Pipelines pipeline events with Unity Catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7362f006-ac49-4f07-981f-c9d26d462f0c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Accessing the Event log table from Unity Catalog."
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM demos.dbdemos_retail_c360.dbdemos_retail_c360_event_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb9867c8-c86f-43d1-8ca5-fa599da0b5e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Analyzing event log table structure\n",
    "\n",
    "The `details` column contains metadata about each Event sent to the Event Log. There are different fields depending on what type of Event it is. Some examples include:\n",
    "* `user_action` Events occur when taking actions like creating the pipeline\n",
    "* `flow_definition` Events occur when a pipeline is deployed or updated and have lineage, schema, and execution plan information\n",
    "  * `output_dataset` and `input_datasets` - output table/view and its upstream table(s)/view(s)\n",
    "  * `flow_type` - whether this is a complete or append flow\n",
    "  * `explain_text` - the Spark explain plan\n",
    "* `flow_progress` Events occur when a data flow starts running or finishes processing a batch of data\n",
    "  * `metrics` - currently contains `num_output_rows`\n",
    "  * `data_quality` - contains an array of the results of the data quality rules for this particular dataset\n",
    "    * `dropped_records`\n",
    "    * `expectations`\n",
    "      * `name`, `dataset`, `passed_records`, `failed_records`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a55513dc-1412-4234-acf8-8eef2f9ae0a7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Lineage Information"
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  details:flow_definition.output_dataset,\n",
    "  details:flow_definition.input_datasets,\n",
    "  details:flow_definition.flow_type,\n",
    "  details:flow_definition.schema,\n",
    "  details:flow_definition\n",
    "FROM demos.dbdemos_retail_c360.dbdemos_retail_c360_event_logs\n",
    "WHERE details:flow_definition IS NOT NULL\n",
    "ORDER BY timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca40a2fa-0803-4e78-b53e-7f43b7c072cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Quality Results"
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  id,\n",
    "  expectations.dataset,\n",
    "  expectations.name,\n",
    "  expectations.failed_records,\n",
    "  expectations.passed_records\n",
    "FROM(\n",
    "  SELECT \n",
    "    id,\n",
    "    timestamp,\n",
    "    details:flow_progress.metrics,\n",
    "    details:flow_progress.data_quality.dropped_records,\n",
    "    explode(from_json(details:flow_progress:data_quality:expectations\n",
    "             ,schema_of_json(\"[{'name':'str', 'dataset':'str', 'passed_records':42, 'failed_records':42}]\"))) expectations\n",
    "  FROM demos.dbdemos_retail_c360.dbdemos_retail_c360_event_logs\n",
    "  WHERE details:flow_progress.metrics IS NOT NULL) data_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc558c48-a6f4-4b32-9fba-00f5428fb945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## That's it! Our data quality metrics are ready! \n",
    "\n",
    "Our datable is now ready be queried using DBSQL. Open the <a dbdemos-dashboard-id=\"sdp-quality-stat\" href='/sql/dashboardsv3/01f0f16ad89a1a239643fd28b74e8521' target=\"_blank\">Data Quality Dashboard</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01.2-SDP-churn-expectation-dashboard-data-prep",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
