{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "7f5ed0e6-201a-4b25-9362-7022f8b7224c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Orchestrating the End-to-End Workflow: From Data to Action\n",
    "\n",
    "\n",
    "## Finding Your Rhythm: Real-time vs. Scheduled\n",
    "\n",
    "Every business has its own pulse. We need to match our technical architecture to this natural cadence:\n",
    "\n",
    "**Option 1: Always-On** ‚ö°  \n",
    "Configure SDP pipelines in continuous mode for streaming insights that capture customer signals as they happen.\n",
    "\n",
    "**Option 2: Efficient Cycles** ‚è±Ô∏è  \n",
    "Wake your compute on a scheduled basis, process new data incrementally, and then release resources.\n",
    "\n",
    "## Our Blueprint: The Hourly Retention Cycle\n",
    "\n",
    "For our retail business, an hourly cadence hits the sweet spot:\n",
    "\n",
    "1. **Data Refresh** üìä - SDP pipeline activates to ingest the latest customer data\n",
    "2. **Dashboard Update** üìà - DBSQL dashboards automatically refresh\n",
    "3. **Model Retraining** üß† - ML models adapt to evolving customer behaviors\n",
    "4. **Triggered Interventions** üéØ - GenAI deploys personalized retention campaigns\n",
    "\n",
    "This creates a closed-loop system where insights drive actions, actions generate new data, and new data refines future insights‚Äîall automatically.\n",
    "\n",
    "<div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "<strong>üí° Pro Tip:</strong> During peak seasons or special promotions, consider shifting to continuous mode for real-time responsiveness, then return to scheduled intervals during normal operations.\n",
    "</div>\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=7405609900705693&notebook=%2F06-Workflow-orchestration%2F06-Workflow-orchestration-churn&demo_name=lakehouse-retail-c360&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-retail-c360%2F06-Workflow-orchestration%2F06-Workflow-orchestration-churn&version=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "f9fc3b05-2dae-400f-9e17-3ffed456a864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Orchestrating our Churn pipeline with Databricks Workflows\n",
    "\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"600px\" src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/cross_demo_assets/dbdemos-workflow-churn-1.png?raw=true\" />\n",
    "\n",
    "With Databricks Lakehouse, no need for external orchestrator. We can use [Workflows](/#job/list) (available on the left menu) to orchestrate our Churn pipeline within a few click.\n",
    "\n",
    "\n",
    "\n",
    "###  Orchestrate anything anywhere\n",
    "With workflow, you can run diverse workloads for the full data and AI lifecycle on any cloud. Orchestrate Spark Declarative Pipelines and Jobs for SQL, Spark, notebooks, dbt, ML models and more.\n",
    "\n",
    "### Simple - Fully managed\n",
    "Remove operational overhead with a fully managed orchestration service, so you can focus on your workflows not on managing your infrastructure.\n",
    "\n",
    "### Proven reliability\n",
    "Have full confidence in your workflows leveraging our proven experience running tens of millions of production workloads daily across AWS, Azure and GCP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "33ff8f1f-e8fc-483b-b553-42fed4d94299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating your workflow\n",
    "\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"600px\" src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/cross_demo_assets/dbdemos-workflow-churn-3.png?raw=true\" />\n",
    "\n",
    "A Databricks Workflow is composed of Tasks.\n",
    "\n",
    "Each task can trigger a specific job:\n",
    "\n",
    "* Spark Declarative Pipelines\n",
    "* SQL query / dashboard\n",
    "* Model retraining / inference\n",
    "* Notebooks\n",
    "* dbt\n",
    "* ...\n",
    "\n",
    "In this example, can see our 3 tasks:\n",
    "\n",
    "* Start the SDP pipeline to ingest new data and refresh our tables\n",
    "* Refresh the DBSQL dashboard (and potentially notify downstream applications)\n",
    "* Retrain our Churn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8947f90-872b-44e2-9004-0156cd4cb802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A workflow was created as part of this demo. Open the <a dbdemos-workflow-id=\"init-job\" href=\"#job/395974101526946/tasks\" target=\"_blank\">C360 Churn Workflow</a> to start exploring Databricks orchestration capabilities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "494a095e-364e-4e83-a9d7-13df35c76920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Monitoring your runs\n",
    "\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"600px\" src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/cross_demo_assets/dbdemos-workflow-tasks.png?raw=true\" />\n",
    "\n",
    "Once your workflow is created, we can access historical runs and receive alerts if something goes wrong!\n",
    "\n",
    "In the screenshot we can see that our workflow had multiple errors, with different runtime, and ultimately got fixed.\n",
    "\n",
    "Workflow monitoring includes errors, abnormal job duration and more advanced control!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a48f146-0ee0-4131-9181-816ac8a6bdd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Not only Datatabricks Lakehouse let you ingest, analyze and infer churn, it also provides a best-in-class orchestrator to offer your business fresh insight making sure everything works as expected!\n",
    "\n",
    "[Go back to introduction]($../00-churn-introduction-lakehouse)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "06-Workflow-orchestration-churn",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
